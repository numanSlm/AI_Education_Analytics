\documentclass[]{report}
\usepackage[notransparent]{svg}
\usepackage{svg-extract}
\usepackage{hyperref}
\usepackage{adjustbox}
\usepackage{multirow}
\hypersetup{
	colorlinks=true,
	linkcolor=blue,
	filecolor=blue,      
	urlcolor=blue,
	pdfpagemode=FullScreen,
}
 \usepackage{amsmath}
 
\usepackage{subcaption}

\usepackage{array}
 \usepackage{etoolbox}
 \makeatletter
 \patchcmd{\section}{\if@openright\cleardoublepage\else\clearpage\fi}{}{}{}
\usepackage[left=0.8in,top=1in,right=0.8in,bottom=1in]{geometry}

\begin{document}
\begin{titlepage}
	\begin{center}
		\vspace*{1cm}

		\includesvg{ConLogo}
		
		\vspace*{2cm}
		
		\textbf{\Large COMP 6721 Applied Artificial Intelligence}
		
		\vspace{0.5cm}
		Professor Ren√© Witte
		
		\vspace{1.5cm}
		\textbf{Group Name:}\\
		NS 01
		\vspace{1.5cm}
		
		\textbf{Group Members:}\\
		Dara Rahmat Samii (40281972)\\ Numan Salim Shaikh (40266934) \\ Shahab Amrollahibioki (40292670)
		
		
		\vfill
		
		\textbf{GitHub Link:}\\
		\href{https://github.com/DaraSamii/A.I.ducation-Analytics}{github.com/DaraSamii/A.I.ducation-Analytics}
		
		\vfill

		
		November 2023
		
	\end{center}
\end{titlepage}
\newpage

\include{part1.tex}
\include{part2.tex}
\include{plots.tex}
\chapter{Fine Tune and Bias Analysis}

In the preceding chapter, it was determined that among different variations of the ResNet model, the configuration with a kernel size of 5, featuring 8 residual blocks, 2 fully connected layers, and 16 channels in each block, achieved the highest accuracy compared to other model variants. In this chapter, the model will undergo more robust training by employing K-fold splitting to achieve a more accurate assessment. Subsequently, a sample of the dataset was labeled according to gender and age, and a bias analysis was conducted on these labeled samples.
\section{K-fold}

The K-fold train-test split was employed to attain more accurate results. It is evident that the metrics for all 10 folds are closely aligned. The highest accuracy was observed during the 8th fold, registering at $0.6618$ percent.

\begin{table}[h]
	\centering
	\caption{Table of K-Fold Macro Metrics}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		\textbf{fold} & \textbf{Max Accuracy} & \textbf{Recall} & \textbf{Precision} & \textbf{F1 Score} \\ \hline
		0       & 0.648218  & 0.649344  & 0.651463  & 0.647351  \\ \hline
		1       & 0.652767  & 0.655904  & 0.661843  & 0.655096  \\ \hline
		2       & 0.636088  & 0.641474  & 0.638708  & 0.63829   \\ \hline
		3       & 0.645944  & 0.65147   & 0.656257  & 0.651095  \\ \hline
		4       & 0.633055  & 0.632776  & 0.639112  & 0.632137  \\ \hline
		5       & 0.648218  & 0.653172  & 0.667303  & 0.652077  \\ \hline
		6       & 0.625474  & 0.62449   & 0.649467  & 0.626003  \\ \hline
		7       & 0.633813  & 0.635683  & 0.651144  & 0.637339  \\ \hline
		8       & \textbf{0.661865}  & 0.660588  & 0.65694   & 0.657756  \\ \hline
		9       & 0.636846  & 0.642635  & 0.655244  & 0.643859  \\ \hline \hline
		Average & 0.6422288 & 0.6447536 & 0.6527481 & 0.6441003 \\ \hline
	\end{tabular}
\end{table}

\begin{table}[]
	\centering
	\caption{Table of K-Fold Micro Metrics}
	\begin{tabular}{|c|c|c|c|c|}
		\hline
		\textbf{fold} & \textbf{Max Accuracy} & \textbf{Recall} & \textbf{Precision} & \textbf{F1 Score} \\ \hline
		0       & 0.648218  & 0.648218  & 0.648218  & 0.648218  \\ \hline
		1       & 0.652767  & 0.652767  & 0.652767  & 0.652767  \\ \hline
		2       & 0.636088  & 0.636088  & 0.636088  & 0.636088  \\ \hline
		3       & 0.645944  & 0.645944  & 0.645944  & 0.645944  \\ \hline
		4       & 0.633055  & 0.633055  & 0.633055  & 0.633055  \\ \hline
		5       & 0.648218  & 0.648218  & 0.648218  & 0.648218  \\ \hline
		6       & 0.625474  & 0.625474  & 0.625474  & 0.625474  \\ \hline
		7       & 0.633813  & 0.633813  & 0.633813  & 0.633813  \\ \hline
		8       & \textbf{0.661865}  & 0.661865  & 0.661865  & 0.661865  \\ \hline
		9       & 0.636846  & 0.636846  & 0.636846  & 0.636846  \\ \hline
		Average & 0.6422288 & 0.6422288 & 0.6422288 & 0.6422288 \\ \hline
	\end{tabular}
\end{table}

\section{Bias Analysis}

Approximately 700 images were randomly selected for each emotion. Since the original dataset lacked labels, manual annotation was performed to determine the age and gender of each face. The specific breakdown for the sample images is as follows:
\begin{enumerate}
	\item Angry images:  711
	\item Bored images: 634
	\item Focused images: 618
	\item Neutral images: 747
\end{enumerate}

The distribution of images based on gender and age is illustrated in Figure \ref{fig:bias}. The percentage of facial expressions between females and males is found to be insubstantial, suggesting that the model distinguishes emotions adequately with minimal disparity between the two genders. Conversely, the proportion of child images is notably smaller than that of adult images, raising suspicions of significant disparities in the model's performance.

\begin{figure}[h]
	\centering
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includesvg[width=\linewidth]{imgs/gender.svg}
		\caption{Distribution of images under the classification of gender}
		\label{fig:gender}
	\end{subfigure}
	\begin{subfigure}{0.48\linewidth}
		\centering
		\includesvg[width=\linewidth]{imgs/age.svg}
		\caption{Distribution of images under the classification of gender}
		\label{fig:age}
	\end{subfigure}
\caption{Distribution of images among the different classification}
\label{fig:bias}
\end{figure}


\begin{table}[]
	\centering
	\caption{Model's metric on different genders and ages}
	\begin{tabular}{|c|c|c|cc|cc|cc|}
		\hline
		\multirow{2}{*}{Attribute} &
		\multirow{2}{*}{Group} &
		\multirow{2}{*}{Accuracy} &
		\multicolumn{2}{c|}{precision} &
		\multicolumn{2}{c|}{recall} &
		\multicolumn{2}{c|}{F1 score} \\ \cline{4-9} 
		&         &        & \multicolumn{1}{c|}{macro}  & micro  & \multicolumn{1}{c|}{macro}  & micro  & \multicolumn{1}{c|}{macro}  & micro  \\ \hline
		\multirow{3}{*}{gender} & male    & 0.7651 & \multicolumn{1}{c|}{0.7568} & 0.7651 & \multicolumn{1}{c|}{0.7449} & 0.7651 & \multicolumn{1}{c|}{0.7484} & 0.7651 \\ \cline{2-9} 
		& female  & 0.7489 & \multicolumn{1}{c|}{0.7495} & 0.7489 & \multicolumn{1}{c|}{0.7609} & 0.7489 & \multicolumn{1}{c|}{0.7456} & 0.7489 \\ \cline{2-9} 
		& average & 0.7570 & \multicolumn{1}{c|}{0.7531} & 0.7570 & \multicolumn{1}{c|}{0.7529} & 0.7570 & \multicolumn{1}{c|}{0.7470} & 0.7570 \\ \hline \hline
		\multirow{3}{*}{age}    & Adult   & 0.7687 & \multicolumn{1}{c|}{0.7651} & 0.7687 & \multicolumn{1}{c|}{0.7607} & 0.7687 & \multicolumn{1}{c|}{0.7602} & 0.7687 \\ \cline{2-9} 
		& Child   & 0.7090 & \multicolumn{1}{c|}{0.6998} & 0.7090 & \multicolumn{1}{c|}{0.7313} & 0.7090 & \multicolumn{1}{c|}{0.6969} & 0.7090 \\ \cline{2-9} 
		& average & 0.7388 & \multicolumn{1}{c|}{0.7324} & 0.7388 & \multicolumn{1}{c|}{0.7460} & 0.7388 & \multicolumn{1}{c|}{0.7286} & 0.7388 \\ \hline
	\end{tabular}
	\label{tab:bias}
\end{table}


As anticipated, as indicated in Table \ref{tab:bias}, it is evident that the model's performance is significantly more accurate when the faces belong to adults rather than children, showing an approximate 7 percent difference. Conversely, the model's metrics on female and male faces exhibit relative similarity.

\subsection{mitigating and fixing biases}


The sole observed bias pertains to the model exhibiting lower accuracy on images featuring children's faces. In response, a strategic approach was adopted, involving an increased emphasis on images labeled as 'child' during the model's retraining process. The resulting dataset, enriched with a greater abundance of children's images, is visually represented in Figure \ref{fig:child}.


\begin{figure}
	\centering
	\includesvg[width=0.6\linewidth]{imgs/child.svg}
	\caption{Distribution of images under the classification of age in retraining data}
	\label{fig:child}
\end{figure}

After retraining the data and evaluating the model with labeled data, it is evident that the nearly 7 percent gap between children and adults has been closed. The final model demonstrates a fair absence of bias.The final Bias Table can be seen in \ref{tab:rebias}
 \begin{table}[h]
 	\centering
 	\caption{Retrained Model performance on different genders and ages}
 	\begin{tabular}{|c|c|c|cc|cc|cc|}
 		\hline
 		\multirow{2}{*}{Attribute} &
 		\multirow{2}{*}{Group} &
 		\multirow{2}{*}{Accuracy} &
 		\multicolumn{2}{c|}{precision} &
 		\multicolumn{2}{c|}{recall} &
 		\multicolumn{2}{c|}{F1 score} \\ \cline{4-9} 
 		&         &        & \multicolumn{1}{c|}{macro}  & micro  & \multicolumn{1}{c|}{macro}  & micro  & \multicolumn{1}{c|}{macro}  & micro  \\ \hline
 		\multirow{3}{*}{gender} & male    & 0.7675 & \multicolumn{1}{c|}{0.7450} & 0.7675 & \multicolumn{1}{c|}{0.7061} & 0.7675 & \multicolumn{1}{c|}{0.7307} & 0.7675 \\ \cline{2-9} 
 		& female  & 0.7565 & \multicolumn{1}{c|}{0.7481} & 0.7565 & \multicolumn{1}{c|}{0.7624} & 0.7565 & \multicolumn{1}{c|}{0.7438} & 0.7565 \\ \cline{2-9} 
 		& average & 0.7620 & \multicolumn{1}{c|}{0.7466} & 0.7620 & \multicolumn{1}{c|}{0.7342} & 0.7620 & \multicolumn{1}{c|}{0.7372} & 0.7620 \\ \hline
 		\multirow{3}{*}{age}    & Adult   & 0.7699 & \multicolumn{1}{c|}{0.7768} & 0.7699 & \multicolumn{1}{c|}{0.7844} & 0.7699 & \multicolumn{1}{c|}{0.7476} & 0.7699 \\ \cline{2-9} 
 		& Child   & 0.7507 & \multicolumn{1}{c|}{0.7465} & 0.7507 & \multicolumn{1}{c|}{0.7547} & 0.7507 & \multicolumn{1}{c|}{0.7401} & 0.7507 \\ \cline{2-9} 
 		& average & 0.7603 & \multicolumn{1}{c|}{0.7617} & 0.7603 & \multicolumn{1}{c|}{0.7695} & 0.7603 & \multicolumn{1}{c|}{0.7438} & 0.7603 \\ \hline
 	\end{tabular}
 	\label{tab:rebias}
 \end{table}
\chapter*{Acknowledgments}

This project was undertaken as part of the requirements for COMP 6721: Applied Artificial Inteligence, lectured by Professor Rene Witte at Concordia University, Montreal, Canada. The report was meticulously prepared using the \LaTeX\ typesetting language on the \href{https://www.overleaf.com/}{Overleaf} platform. Additionally, schematic diagrams were crafted using \href{https://app.diagrams.net/}{draw.io}.Compute Canada Alliance, Cedar Computer located in Simon Fraser University, Vancouver, Canada, was used to perform High Performance Computings and training the models.


\bibliographystyle{ieeetr}
\bibliography{bib} 
\end{document}
